logging:
  filename: logging.log
  format: ' %(asctime)s - %(levelname)s -%(filename)s - %(funcName)s >> %(message)s'
  console_level: 20
  file_level: 10
wandb:
  project: marigold
dataset:
  train:
    name: mixed
    prob_ls:
    - 0.9
    - 0.1
    dataset_list:
    - name: hypersim
      disp_name: hypersim_train
      dir: hypersim/hypersim_processed_train.tar
      filenames: data_split/hypersim/filename_list_train_filtered.txt
      resize_to_hw:
      - 480
      - 640
    - name: vkitti
      disp_name: vkitti_train
      dir: vkitti
      filenames: data_split/vkitti/vkitti_train.txt
      kitti_bm_crop: true
      valid_mask_crop: null
  val:
  - name: hypersim
    disp_name: hypersim_val_small_80
    dir: hypersim/hypersim_processed_val.tar
    filenames: data_split/hypersim/filename_list_val_filtered_small_80.txt
    resize_to_hw:
    - 480
    - 640
  vis:
  - name: hypersim
    disp_name: hypersim_vis
    dir: hypersim/hypersim_processed_val.tar
    filenames: data_split/hypersim/selected_vis_sample.txt
    resize_to_hw:
    - 480
    - 640
model:
  name: marigold_pipeline
  pretrained_path: stable-diffusion-2
  latent_scale_factor: 0.18215
base_config:
- config/logging.yaml
- config/wandb.yaml
- config/dataset/dataset_train.yaml
- config/dataset/dataset_val.yaml
- config/dataset/dataset_vis.yaml
- config/model_sdv2.yaml
pipeline:
  name: MarigoldPipeline
  kwargs:
    scale_invariant: true
    shift_invariant: true
depth_normalization:
  type: scale_shift_depth
  clip: true
  norm_min: -1.0
  norm_max: 1.0
  min_max_quantile: 0.02
augmentation:
  lr_flip_p: 0.5
dataloader:
  num_workers: 2
  effective_batch_size: 32
  max_train_batch_size: 2
  seed: 2024
trainer:
  name: MarigoldTrainer
  training_noise_scheduler:
    pretrained_path: stable-diffusion-2
  init_seed: 2024
  save_period: 50
  backup_period: 2000
  validation_period: 2000
  visualization_period: 2000
multi_res_noise:
  strength: 0.9
  annealed: true
  downscale_strategy: original
gt_depth_type: depth_one_over_norm
gt_mask_type: valid_mask_one_over
max_epoch: 10000
max_iter: 15000
optimizer:
  name: Adam
loss:
  name: mse_loss
  kwargs:
    reduction: mean
lr: 3.0e-05
lr_scheduler:
  name: IterExponential
  kwargs:
    total_iter: 25000
    final_ratio: 0.01
    warmup_steps: 100
validation:
  denoising_steps: 50
  ensemble_size: 1
  processing_res: 0
  match_input_res: false
  resample_method: bilinear
  main_val_metric: abs_relative_difference
  main_val_metric_goal: minimize
  init_seed: 2024
eval:
  alignment: least_square
  align_max_res: null
  eval_metrics:
  - abs_relative_difference
  - squared_relative_difference
  - rmse_linear
  - rmse_log
  - log10
  - delta1_acc
  - delta2_acc
  - delta3_acc
  - i_rmse
  - silog_rmse
